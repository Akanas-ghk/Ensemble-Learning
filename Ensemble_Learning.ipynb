{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **THEORY**"
      ],
      "metadata": {
        "id": "75mG4rAjQOpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **Q1. Can we use Bagging for regression problems?**\n",
        "\n",
        "Yes, Bagging can be used for regression problems. In this case, base regressors (e.g., Decision Trees) are trained on different bootstrap samples, and the final prediction is made by averaging the outputs of all base models. This reduces variance and helps in building a more stable and accurate regression model, especially useful for datasets with high variance or overfitting issues.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q2. What is the difference between multiple model training and single model training?**\n",
        "\n",
        "Single model training builds one predictive model using the entire dataset. In contrast, multiple model training (used in ensemble methods) builds several models and combines their predictions. This improves performance by reducing variance (Bagging), bias (Boosting), or both. Multiple models can generalize better and handle data noise or anomalies more effectively than a single model.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q3. Explain the concept of feature randomness in Random Forest.**\n",
        "\n",
        "In Random Forest, feature randomness means that at each split of a decision tree, a **random subset of features** is selected rather than considering all features. This introduces diversity among trees, reducing correlation and overfitting. It improves the model’s generalization by ensuring that each tree explores different patterns in the data.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q4. What is OOB (Out-of-Bag) Score?**\n",
        "\n",
        "OOB Score is a performance estimate in Bagging and Random Forest models. When using bootstrap sampling, some data points are not included in a tree's training set. These \"out-of-bag\" samples are used as a validation set to evaluate the model. Averaging the accuracy over these samples gives the OOB score, which acts like cross-validation.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q5. How can you measure the importance of features in a Random Forest model?**\n",
        "\n",
        "Random Forest measures feature importance by observing how much each feature decreases impurity (like Gini or entropy) across all trees. It can also be measured by the impact on the model’s accuracy when a feature’s values are randomly shuffled. Higher importance means the feature contributes more to the decision-making process.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q6. Explain the working principle of a Bagging Classifier.**\n",
        "\n",
        "A Bagging Classifier builds multiple instances of the same base model (like Decision Trees) using different bootstrap samples. Each model is trained independently and makes predictions. The final prediction is made by majority voting (for classification). This helps reduce variance, improve stability, and protect against overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q7. How do you evaluate a Bagging Classifier’s performance?**\n",
        "\n",
        "The performance of a Bagging Classifier is evaluated using metrics like **Accuracy**, **Precision**, **Recall**, **F1-score**, or **AUC-ROC** depending on the problem. Additionally, **Out-of-Bag (OOB) Score** and **cross-validation** can be used for internal validation without needing a separate validation set, providing robust performance estimates.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q8. How does a Bagging Regressor work?**\n",
        "\n",
        "A Bagging Regressor trains several base regression models on different bootstrap samples. Each model gives a numeric output, and the final prediction is the **average** of all these outputs. This approach reduces variance, increases robustness, and provides better generalization, especially when base models are prone to overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "#**Q9. What is the main advantage of ensemble techniques?**\n",
        "\n",
        "The main advantage of ensemble techniques is their ability to **improve predictive performance** by combining multiple models. They reduce variance (Bagging), bias (Boosting), or both, and are more robust to noise and overfitting. They also tend to generalize better than single models in most real-world scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q10. What is the main challenge of ensemble methods?**\n",
        "\n",
        "The main challenge of ensemble methods is **increased complexity and computation time**. Training and combining multiple models require more resources, making interpretation difficult. Additionally, if not tuned properly, ensembles can still overfit or underperform, especially with small or highly imbalanced datasets.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q11. Explain the key idea behind ensemble techniques.**\n",
        "\n",
        "The key idea behind ensemble techniques is that a **group of weak learners** can come together to form a **strong learner**. By combining predictions from multiple models—each trained differently—we get better accuracy, reduced errors, and more stable predictions. Methods like Bagging, Boosting, and Stacking implement this principle.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q12. What is a Random Forest Classifier?**\n",
        "\n",
        "A Random Forest Classifier is an ensemble learning method that builds a large number of decision trees on random subsets of data and features. It predicts the class by majority voting. Random Forest combines the simplicity of Decision Trees with the power of ensemble learning to increase accuracy and prevent overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q13. What are the main types of ensemble techniques?**\n",
        "\n",
        "The main types of ensemble techniques are:\n",
        "\n",
        "1. **Bagging (Bootstrap Aggregating)** – reduces variance\n",
        "2. **Boosting** – reduces bias\n",
        "3. **Stacking** – combines multiple algorithms using a meta-learner\n",
        "   Each type improves prediction performance by leveraging the strengths of individual models.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q14. What is ensemble learning in machine learning?**\n",
        "\n",
        "Ensemble learning is a technique where **multiple models** (often weak learners) are trained and combined to solve a particular problem. The idea is to leverage the strengths of various models to improve overall performance, robustness, and accuracy compared to individual models.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q15. When should we avoid using ensemble methods?**\n",
        "\n",
        "Avoid ensemble methods when the dataset is **very small**, as complex models may overfit. Also, if **interpretability** is critical (e.g., in healthcare or law), simpler models are preferred. Ensemble methods may not offer much benefit when a single model already performs well and resources are limited.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q16. How does Bagging help in reducing overfitting?**\n",
        "\n",
        "Bagging reduces overfitting by training models on **random bootstrap samples**. Since each model sees a slightly different version of the data, it reduces the model's dependence on any single pattern. Combining predictions smooths out noise and variance, making the final model more stable and generalizable.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q17. Why is Random Forest better than a single Decision Tree?**\n",
        "\n",
        "Random Forest is better than a single Decision Tree because it combines multiple trees built on different data and features, reducing overfitting and improving accuracy. While a single tree is highly sensitive to data changes, Random Forest generalizes better by averaging multiple uncorrelated trees.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q18. What is the role of bootstrap sampling in Bagging?**\n",
        "\n",
        "Bootstrap sampling is the process of creating multiple datasets by **random sampling with replacement** from the original data. Each base model is trained on one such sample, ensuring diversity among models. This randomness helps Bagging reduce variance and avoid overfitting, leading to better generalization.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q19. What are some real-world applications of ensemble techniques?**\n",
        "\n",
        "Ensemble techniques are widely used in real-world applications like:\n",
        "\n",
        "* **Fraud detection**\n",
        "* **Spam filtering**\n",
        "* **Medical diagnosis**\n",
        "* **Credit scoring**\n",
        "* **Stock market prediction**\n",
        "  They are also commonly used in data science competitions (e.g., Kaggle) where performance is key.\n",
        "\n",
        "---\n",
        "\n",
        "# **Q20. What is the difference between Bagging and Boosting?**\n",
        "\n",
        "* **Bagging** trains models **independently** on random data samples and combines them to reduce variance.\n",
        "* **Boosting** trains models **sequentially**, with each new model focusing on errors made by the previous ones, reducing bias.\n",
        "  Bagging uses **parallel learning**; Boosting uses **sequential learning**. Both improve accuracy but in different ways.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "flWR-u71QTh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KLmuMkg4RYjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy**"
      ],
      "metadata": {
        "id": "I24Y8WZuRaJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "bagging_model = BaggingClassifier(estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "fefhEkcRj09e",
        "outputId": "3c9a8e95-8295-420a-988f-05027f1325ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50,\n",
              "                  random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50,\n",
              "                  random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BaggingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.BaggingClassifier.html\">?<span>Documentation for BaggingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50,\n",
              "                  random_state=42)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: DecisionTreeClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)**"
      ],
      "metadata": {
        "id": "AJbFnpw7kJwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define base estimator\n",
        "base_estimator = DecisionTreeRegressor()\n",
        "\n",
        "# Train Bagging Regressor\n",
        "bagging_regressor = BaggingRegressor(estimator=base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "bagging_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = bagging_regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Bagging Regressor MSE:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp6o1wwMkocF",
        "outputId": "3e842500-080e-492c-b53a-43e291d9a7ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 2987.0073593984966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores**"
      ],
      "metadata": {
        "id": "mOGu5aC0lEDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_classifier.feature_importances_\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Top Feature Importances:\\n\", importance_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ1szE7dlSz9",
        "outputId": "a66d8493-5b94-41ba-ecca-5f92d41a7d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Feature Importances:\n",
            "                  Feature  Importance\n",
            "7    mean concave points    0.141934\n",
            "27  worst concave points    0.127136\n",
            "23            worst area    0.118217\n",
            "6         mean concavity    0.080557\n",
            "20          worst radius    0.077975\n",
            "22       worst perimeter    0.074292\n",
            "2         mean perimeter    0.060092\n",
            "3              mean area    0.053810\n",
            "26       worst concavity    0.041080\n",
            "0            mean radius    0.032312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q24. Train a Random Forest Regressor and compare its performance with a single Decision Tree**"
      ],
      "metadata": {
        "id": "dC6cn9haleSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train single Decision Tree Regressor\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "dt_mse = mean_squared_error(y_test, dt_pred)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "print(\"Decision Tree MSE:\", dt_mse)\n",
        "print(\"Random Forest MSE:\", rf_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_V4W1Lslmse",
        "outputId": "dd6236bd-a950-4186-82f0-603425209dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 5697.789473684211\n",
            "Random Forest MSE: 2859.641982706767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier**"
      ],
      "metadata": {
        "id": "t3KKEQbdlsVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train Random Forest with OOB score enabled\n",
        "rf_model = RandomForestClassifier(n_estimators=100, oob_score=True, bootstrap=True, random_state=42)\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "# Print OOB Score\n",
        "print(\"Out-of-Bag (OOB) Score:\", rf_model.oob_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcpTy6IomHDP",
        "outputId": "88fe1a0c-edfb-4481-885c-92eca0d2424f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag (OOB) Score: 0.961335676625659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q26. Train a Bagging Classifier using SVM as a base estimator and print accuracy**"
      ],
      "metadata": {
        "id": "pVe05v2amO25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train Random Forest with OOB score enabled\n",
        "rf_model = RandomForestClassifier(n_estimators=100, oob_score=True, bootstrap=True, random_state=42)\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "# Print OOB Score\n",
        "print(\"Out-of-Bag (OOB) Score:\", rf_model.oob_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJAZDVzCmlFd",
        "outputId": "d98a000e-6ef6-46e7-f5b6-f8bded5e5fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag (OOB) Score: 0.961335676625659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q27. Train a Random Forest Classifier with different numbers of trees and compare accuracy**"
      ],
      "metadata": {
        "id": "jLnVrIrqoL_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Try different numbers of trees\n",
        "for n_trees in [10, 50, 100, 200]:\n",
        "    rf_model = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {n_trees} trees: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_nG3g_sqRmN",
        "outputId": "23df1b4f-fba7-4610-ec14-954449602ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with 10 trees: 1.0000\n",
            "Accuracy with 50 trees: 1.0000\n",
            "Accuracy with 100 trees: 1.0000\n",
            "Accuracy with 200 trees: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score**"
      ],
      "metadata": {
        "id": "yI1indaorFaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load data\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Base Logistic Regression\n",
        "log_reg = LogisticRegression(max_iter=1000)  # Increased iterations\n",
        "\n",
        "# Bagging Classifier\n",
        "bagging_logreg = BaggingClassifier(estimator=log_reg, n_estimators=10, random_state=42)\n",
        "bagging_logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_prob = bagging_logreg.predict_proba(X_test_scaled)[:, 1]\n",
        "print(\"Bagging Classifier with Logistic Regression AUC Score:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFnDyaqcr-oE",
        "outputId": "5180cf31-a178-4730-aa57-935759da635f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier with Logistic Regression AUC Score: 0.99812734082397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q29. Train a Random Forest Regressor and analyze feature importance scores**\n"
      ],
      "metadata": {
        "id": "IO_3ZkWTsElS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Analyze feature importance\n",
        "importances = rf_regressor.feature_importances_\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Top Feature Importances in Random Forest Regressor:\\n\", importance_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgq3DWcosC17",
        "outputId": "2209b43a-b895-4f74-ef9d-54ae704360a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Feature Importances in Random Forest Regressor:\n",
            "   Feature  Importance\n",
            "2     bmi    0.400000\n",
            "8      s5    0.166602\n",
            "3      bp    0.104839\n",
            "9      s6    0.071358\n",
            "6      s3    0.061730\n",
            "0     age    0.058633\n",
            "4      s1    0.049191\n",
            "5      s2    0.047138\n",
            "7      s4    0.029427\n",
            "1     sex    0.011082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q30. Train an ensemble model using both Bagging and Random Forest and compare accuracy**"
      ],
      "metadata": {
        "id": "fHTOVIp3sZPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Bagging Classifier using Decision Tree\n",
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "bagging_pred = bagging_model.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "# Compare\n",
        "print(f\"Bagging Classifier Accuracy: {bagging_accuracy:.4f}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {rf_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoXKgPN7tebI",
        "outputId": "8316ca56-35aa-4e83-ca88-77ef6ac6c6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 1.0000\n",
            "Random Forest Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV**"
      ],
      "metadata": {
        "id": "JwULOG53tLw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 3, 5],\n",
        "    'min_samples_split': [2, 4],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Create and run GridSearchCV\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best estimator and accuracy\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Random Forest Accuracy after GridSearchCV:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT0wET3BtLN9",
        "outputId": "feca827d-31c6-4c8f-b356-e5d0c4a52f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Random Forest Accuracy after GridSearchCV: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q32. Train a Bagging Regressor with different numbers of base estimators and compare performance**"
      ],
      "metadata": {
        "id": "BDNKCuV20roq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Evaluate performance for different numbers of estimators\n",
        "for n_estimators in [10, 50, 100, 200]:\n",
        "    model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n_estimators, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"{n_estimators} Estimators - MSE: {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS6IjTm90zdp",
        "outputId": "f4fe5739-4c31-483a-b70e-ad51ac44b2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Estimators - MSE: 3237.53\n",
            "50 Estimators - MSE: 2987.01\n",
            "100 Estimators - MSE: 2908.81\n",
            "200 Estimators - MSE: 2854.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q33. Train a Random Forest Classifier and analyze misclassified samples**"
      ],
      "metadata": {
        "id": "M9w8ikaK09ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Identify misclassified samples\n",
        "misclassified_indices = (y_pred != y_test)\n",
        "misclassified_data = pd.DataFrame(X_test[misclassified_indices], columns=feature_names)\n",
        "misclassified_data['Actual'] = y_test[misclassified_indices]\n",
        "misclassified_data['Predicted'] = y_pred[misclassified_indices]\n",
        "\n",
        "print(\"\\nMisclassified Samples:\\n\", misclassified_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "equJY5Zl1E6j",
        "outputId": "25c2b07a-1668-4bdb-e554-bc1d6e73b668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9707602339181286\n",
            "\n",
            "Misclassified Samples:\n",
            "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        13.34         15.86           86.49      520.0          0.10780   \n",
            "1        13.80         15.79           90.43      584.1          0.10070   \n",
            "2        13.96         17.05           91.43      602.4          0.10960   \n",
            "3        14.48         21.46           94.25      648.2          0.09444   \n",
            "4        15.13         29.81           96.71      719.5          0.08320   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.15350         0.11690              0.06987         0.1942   \n",
            "1           0.12800         0.07789              0.05069         0.1662   \n",
            "2           0.12790         0.09789              0.05246         0.1908   \n",
            "3           0.09947         0.12040              0.04938         0.2075   \n",
            "4           0.04605         0.04686              0.02739         0.1852   \n",
            "\n",
            "   mean fractal dimension  ...  worst perimeter  worst area  worst smoothness  \\\n",
            "0                 0.06902  ...            96.66       614.9            0.1536   \n",
            "1                 0.06566  ...           110.30       812.4            0.1411   \n",
            "2                 0.06130  ...           108.10       826.0            0.1512   \n",
            "3                 0.05636  ...           108.40       808.9            0.1306   \n",
            "4                 0.05294  ...           110.10       931.4            0.1148   \n",
            "\n",
            "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
            "0            0.47910           0.4858               0.17080          0.3527   \n",
            "1            0.35420           0.2779               0.13830          0.2589   \n",
            "2            0.32620           0.3209               0.13740          0.3068   \n",
            "3            0.19760           0.3349               0.12250          0.3020   \n",
            "4            0.09866           0.1547               0.06575          0.3233   \n",
            "\n",
            "   worst fractal dimension  Actual  Predicted  \n",
            "0                  0.10160       1          0  \n",
            "1                  0.10300       0          1  \n",
            "2                  0.07957       0          1  \n",
            "3                  0.06846       0          1  \n",
            "4                  0.06165       0          1  \n",
            "\n",
            "[5 rows x 32 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "62VIEt9i1LCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train single Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "dt_acc = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "# Train Bagging Classifier\n",
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "bagging_pred = bagging_model.predict(X_test)\n",
        "bagging_acc = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {dt_acc:.4f}\")\n",
        "print(f\"Bagging Classifier Accuracy: {bagging_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSlXp6nb1Tq1",
        "outputId": "f57bdc0c-b4bf-4432-fc78-ef7f038f7e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 1.0000\n",
            "Bagging Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q35. Train a Random Forest Classifier and visualize the confusion matrix**"
      ],
      "metadata": {
        "id": "jHyepAMW1eaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_model.classes_)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Random Forest Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "hPXMRy_P1on1",
        "outputId": "1ca1fa41-f0ac-4e9c-eb53-7ebe52833a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy**"
      ],
      "metadata": {
        "id": "gvsQcLGu1unU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42))\n",
        "]\n",
        "\n",
        "# Meta-learner\n",
        "meta_learner = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Build and train Stacking Classifier\n",
        "stack_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = stack_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m6QP3Ut14At",
        "outputId": "f36752f8-0fc5-4a13-ccb2-1bab8ca710d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q37. Train a Random Forest Classifier and print the top 5 most important features**"
      ],
      "metadata": {
        "id": "aS7PHkIW1-xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Get and print top 5 feature importances\n",
        "importances = rf_model.feature_importances_\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "top_5 = importance_df.sort_values(by='Importance', ascending=False).head(5)\n",
        "\n",
        "print(\"Top 5 Important Features:\\n\", top_5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLn6j6ub6PNt",
        "outputId": "b79de532-00c4-4c98-81b9-a5666344c8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Important Features:\n",
            "                  Feature  Importance\n",
            "7    mean concave points    0.141934\n",
            "27  worst concave points    0.127136\n",
            "23            worst area    0.118217\n",
            "6         mean concavity    0.080557\n",
            "20          worst radius    0.077975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score**"
      ],
      "metadata": {
        "id": "t-l4zW6H6Ulz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier\n",
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1-score:  {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp4RiWwb6dg2",
        "outputId": "0d0293a4-ea15-49a0-ddd2-e24f8b879d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9633\n",
            "Recall:    0.9722\n",
            "F1-score:  0.9677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy**"
      ],
      "metadata": {
        "id": "yPcmEaOB6mE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Evaluate accuracy for different max_depth values\n",
        "for depth in [None, 2, 4, 6, 8, 10]:\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"max_depth={depth}: Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeR0WUCZ6uJ1",
        "outputId": "b8b5dea6-77cc-4c29-e305-287bdb53fb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_depth=None: Accuracy = 1.0000\n",
            "max_depth=2: Accuracy = 1.0000\n",
            "max_depth=4: Accuracy = 1.0000\n",
            "max_depth=6: Accuracy = 1.0000\n",
            "max_depth=8: Accuracy = 1.0000\n",
            "max_depth=10: Accuracy = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance**"
      ],
      "metadata": {
        "id": "a8VtWrF-6zdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Decision Tree base estimator\n",
        "dt_model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=50, random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "dt_mse = mean_squared_error(y_test, dt_pred)\n",
        "\n",
        "# KNeighbors base estimator\n",
        "knn_model = BaggingRegressor(estimator=KNeighborsRegressor(), n_estimators=50, random_state=42)\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "knn_mse = mean_squared_error(y_test, knn_pred)\n",
        "\n",
        "print(f\"Bagging with Decision Tree - MSE: {dt_mse:.2f}\")\n",
        "print(f\"Bagging with KNeighbors     - MSE: {knn_mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtntsA6O69ub",
        "outputId": "c389a4d6-beb4-4b7c-de9d-5009323a8785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging with Decision Tree - MSE: 2987.01\n",
            "Bagging with KNeighbors     - MSE: 3140.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score**"
      ],
      "metadata": {
        "id": "avpTechp7LHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and calculate ROC-AUC\n",
        "y_proba = rf_model.predict_proba(X_test)[:, 1]\n",
        "auc_score = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(\"Random Forest ROC-AUC Score:\", auc_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6IF0grm7SMR",
        "outputId": "f59fe804-e133-4d32-b5b3-3242338fba0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest ROC-AUC Score: 0.9968400940623163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q42. Train a Bagging Classifier and evaluate its performance using cross-validation**"
      ],
      "metadata": {
        "id": "9aQEn9FG7X2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Define Bagging Classifier\n",
        "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(bagging_model, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean Accuracy:\", np.mean(scores))\n",
        "print(\"Standard Deviation:\", np.std(scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDdf8Yya7e1C",
        "outputId": "f0e8392b-b1e3-480e-b4da-25758a4c5a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean Accuracy: 0.9666666666666668\n",
            "Standard Deviation: 0.02108185106778919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q43. Train a Random Forest Classifier and plot the Precision-Recall curve**"
      ],
      "metadata": {
        "id": "fdLSSfV77mlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_scores = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Plot the curve\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()\n",
        "plt.title(\"Precision-Recall Curve for Random Forest\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "xB2eJaKl7v9A",
        "outputId": "c85cd373-b916-4fe3-f07a-b37a55faf515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy**"
      ],
      "metadata": {
        "id": "reGxNBUj7vd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "base_estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42))\n",
        "]\n",
        "\n",
        "# Meta learner\n",
        "meta_learner = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define and train stacking classifier\n",
        "stack_model = StackingClassifier(estimators=base_estimators, final_estimator=meta_learner, cv=5)\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = stack_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Stacking Classifier Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEBaNiHM8Eet",
        "outputId": "20c077d3-4c46-476e-9765-065e14245d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance**"
      ],
      "metadata": {
        "id": "Ur6n8Etk8Kem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Try different max_samples values (fraction of data for each bootstrap sample)\n",
        "for sample_size in [0.5, 0.7, 1.0]:\n",
        "    model = BaggingRegressor(\n",
        "        estimator=DecisionTreeRegressor(),\n",
        "        n_estimators=50,\n",
        "        max_samples=sample_size,\n",
        "        bootstrap=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Bootstrap Sample Size {sample_size:.1f} - MSE: {mse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CChF92Mw8Wdr",
        "outputId": "872df6cb-9084-428d-fee1-946de6cf8ca8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap Sample Size 0.5 - MSE: 2826.94\n",
            "Bootstrap Sample Size 0.7 - MSE: 2797.22\n",
            "Bootstrap Sample Size 1.0 - MSE: 2987.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q46. Train a Random Forest Classifier and evaluate feature importance using permutation importance**"
      ],
      "metadata": {
        "id": "_743HbEM8kZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Permutation importance on test set\n",
        "perm_importance = permutation_importance(rf_model, X_test, y_test, n_repeats=10, random_state=42)\n",
        "\n",
        "# Create a DataFrame for better display\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': perm_importance.importances_mean\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"Top 5 Features by Permutation Importance:\\n\", importance_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpjsfRyc9ZUs",
        "outputId": "6cd89005-2a6e-450e-8cd8-fa535d1a0da3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Features by Permutation Importance:\n",
            "                  Feature  Importance\n",
            "23            worst area    0.011696\n",
            "21         worst texture    0.005848\n",
            "20          worst radius    0.004678\n",
            "27  worst concave points    0.004094\n",
            "14      smoothness error    0.004094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q47. Train a Bagging Classifier and analyze the effect of different max_samples values on accuracy**"
      ],
      "metadata": {
        "id": "c0elJjvK9hW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Evaluate different max_samples settings\n",
        "for sample_fraction in [0.4, 0.6, 0.8, 1.0]:\n",
        "    model = BaggingClassifier(\n",
        "        estimator=DecisionTreeClassifier(),\n",
        "        n_estimators=50,\n",
        "        max_samples=sample_fraction,\n",
        "        bootstrap=True,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"max_samples = {sample_fraction:.1f} → Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op1Rdjgv9p1j",
        "outputId": "3e32b6ac-e5f3-41d2-be88-7aed4d67fb2d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_samples = 0.4 → Accuracy = 1.0000\n",
            "max_samples = 0.6 → Accuracy = 1.0000\n",
            "max_samples = 0.8 → Accuracy = 1.0000\n",
            "max_samples = 1.0 → Accuracy = 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q48. Train a Random Forest Classifier with class weights to handle imbalanced data**"
      ],
      "metadata": {
        "id": "eP39dt_Z9zc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Generate imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,\n",
        "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Train Random Forest with class_weight='balanced'\n",
        "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = rf_model.predict(X_test)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOoDmeRC96fU",
        "outputId": "a36910ee-2ab1-4c65-90b6-ad2e5c50452c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       270\n",
            "           1       0.90      0.60      0.72        30\n",
            "\n",
            "    accuracy                           0.95       300\n",
            "   macro avg       0.93      0.80      0.85       300\n",
            "weighted avg       0.95      0.95      0.95       300\n",
            "\n"
          ]
        }
      ]
    }
  ]
}